{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chisReOxgXLB"
      },
      "outputs": [],
      "source": [
        "HOME_DIR = \"/content/drive/MyDrive/PhD research/LLM Privacy Policy\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install llama-index llama-index-embeddings-huggingface llama-index-llms-llama-cpp pypdf\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip -q install llama-cpp-python"
      ],
      "metadata": {
        "id": "CmjLRzG4ieAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "\n",
        "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
        "from llama_index.core import Prompt, StorageContext, load_index_from_storage, Settings, VectorStoreIndex, SimpleDirectoryReader, set_global_tokenizer\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.llama_cpp import LlamaCPP\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from IPython.display import Markdown, display"
      ],
      "metadata": {
        "id": "DD7h9gIojS-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google ADs"
      ],
      "metadata": {
        "id": "cYIwEfaxu4We"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hereâ€™s a list of some of the organizations we partner with:\n",
        "\n",
        "1. Accenture\n",
        "2. Atento\n",
        "3. Cognizant\n",
        "4. Concentrix\n",
        "5. Regalix / Marketstar\n",
        "6. TDCX / Teledirect\n",
        "7. Teleperformance\n",
        "8. TMJ\n",
        "9. TTEC\n",
        "10. WNS"
      ],
      "metadata": {
        "id": "NShHuKLKu7vP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_embedding_model = 'thenlper/gte-base'  #Alt: thenlper/gte-base, jinaai/jina-embeddings-v2-base-en\n",
        "llm_url = 'https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_K_M.gguf'\n",
        "\n",
        "# Load models and service context\n",
        "embed_model = HuggingFaceEmbedding(model_name=text_embedding_model)\n",
        "llm = LlamaCPP(model_url=llm_url, temperature=0.7, max_new_tokens=256, context_window=4096, generate_kwargs = {\"stop\": [\"<s>\", \"[INST]\", \"[/INST]\"]}, model_kwargs={\"n_gpu_layers\": -1}, verbose=True)\n",
        "# service_context = ServiceContext.from_defaults(llm=llm, embed_model=embed_model, chunk_size=512)\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model\n",
        "Settings.chunk_size = 512"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5t3NnrDQu22T",
        "outputId": "8c38f49f-fa24-4bc2-d974-81201e284e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /tmp/llama_index/models/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q4_K:  193 tensors\n",
            "llama_model_loader: - type q6_K:   33 tensors\n",
            "print_info: file format = GGUF V2\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 3.80 GiB (4.84 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 1\n",
            "load: control token:      2 '</s>' is not marked as EOG\n",
            "load: control token:      1 '<s>' is not marked as EOG\n",
            "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "load: special tokens cache size = 3\n",
            "load: token to piece cache size = 0.1684 MB\n",
            "print_info: arch             = llama\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 4096\n",
            "print_info: n_embd           = 4096\n",
            "print_info: n_layer          = 32\n",
            "print_info: n_head           = 32\n",
            "print_info: n_head_kv        = 32\n",
            "print_info: n_rot            = 128\n",
            "print_info: n_swa            = 0\n",
            "print_info: n_embd_head_k    = 128\n",
            "print_info: n_embd_head_v    = 128\n",
            "print_info: n_gqa            = 1\n",
            "print_info: n_embd_k_gqa     = 4096\n",
            "print_info: n_embd_v_gqa     = 4096\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-06\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 11008\n",
            "print_info: n_expert         = 0\n",
            "print_info: n_expert_used    = 0\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 0\n",
            "print_info: rope scaling     = linear\n",
            "print_info: freq_base_train  = 10000.0\n",
            "print_info: freq_scale_train = 1\n",
            "print_info: n_ctx_orig_yarn  = 4096\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: ssm_d_conv       = 0\n",
            "print_info: ssm_d_inner      = 0\n",
            "print_info: ssm_d_state      = 0\n",
            "print_info: ssm_dt_rank      = 0\n",
            "print_info: ssm_dt_b_c_rms   = 0\n",
            "print_info: model type       = 7B\n",
            "print_info: model params     = 6.74 B\n",
            "print_info: general.name     = LLaMA v2\n",
            "print_info: vocab type       = SPM\n",
            "print_info: n_vocab          = 32000\n",
            "print_info: n_merges         = 0\n",
            "print_info: BOS token        = 1 '<s>'\n",
            "print_info: EOS token        = 2 '</s>'\n",
            "print_info: UNK token        = 0 '<unk>'\n",
            "print_info: LF token         = 13 '<0x0A>'\n",
            "print_info: EOG token        = 2 '</s>'\n",
            "print_info: max token length = 48\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CPU\n",
            "load_tensors: layer   1 assigned to device CPU\n",
            "load_tensors: layer   2 assigned to device CPU\n",
            "load_tensors: layer   3 assigned to device CPU\n",
            "load_tensors: layer   4 assigned to device CPU\n",
            "load_tensors: layer   5 assigned to device CPU\n",
            "load_tensors: layer   6 assigned to device CPU\n",
            "load_tensors: layer   7 assigned to device CPU\n",
            "load_tensors: layer   8 assigned to device CPU\n",
            "load_tensors: layer   9 assigned to device CPU\n",
            "load_tensors: layer  10 assigned to device CPU\n",
            "load_tensors: layer  11 assigned to device CPU\n",
            "load_tensors: layer  12 assigned to device CPU\n",
            "load_tensors: layer  13 assigned to device CPU\n",
            "load_tensors: layer  14 assigned to device CPU\n",
            "load_tensors: layer  15 assigned to device CPU\n",
            "load_tensors: layer  16 assigned to device CPU\n",
            "load_tensors: layer  17 assigned to device CPU\n",
            "load_tensors: layer  18 assigned to device CPU\n",
            "load_tensors: layer  19 assigned to device CPU\n",
            "load_tensors: layer  20 assigned to device CPU\n",
            "load_tensors: layer  21 assigned to device CPU\n",
            "load_tensors: layer  22 assigned to device CPU\n",
            "load_tensors: layer  23 assigned to device CPU\n",
            "load_tensors: layer  24 assigned to device CPU\n",
            "load_tensors: layer  25 assigned to device CPU\n",
            "load_tensors: layer  26 assigned to device CPU\n",
            "load_tensors: layer  27 assigned to device CPU\n",
            "load_tensors: layer  28 assigned to device CPU\n",
            "load_tensors: layer  29 assigned to device CPU\n",
            "load_tensors: layer  30 assigned to device CPU\n",
            "load_tensors: layer  31 assigned to device CPU\n",
            "load_tensors: layer  32 assigned to device CPU\n",
            "load_tensors: tensor 'token_embd.weight' (q4_K) (and 290 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
            "load_tensors:   CPU_Mapped model buffer size =  3891.24 MiB\n",
            "..................................................................................................\n",
            "llama_init_from_model: n_seq_max     = 1\n",
            "llama_init_from_model: n_ctx         = 4096\n",
            "llama_init_from_model: n_ctx_per_seq = 4096\n",
            "llama_init_from_model: n_batch       = 512\n",
            "llama_init_from_model: n_ubatch      = 512\n",
            "llama_init_from_model: flash_attn    = 0\n",
            "llama_init_from_model: freq_base     = 10000.0\n",
            "llama_init_from_model: freq_scale    = 1\n",
            "llama_kv_cache_init: kv_size = 4096, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
            "llama_kv_cache_init: layer 0: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 1: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 2: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 3: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 4: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 5: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 6: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 7: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 8: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 9: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 10: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 11: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 12: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 13: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 14: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 15: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 16: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 17: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 18: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 19: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 20: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 21: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 22: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 23: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 24: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 25: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 26: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 27: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 28: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 29: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 30: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init: layer 31: n_embd_k_gqa = 4096, n_embd_v_gqa = 4096\n",
            "llama_kv_cache_init:        CPU KV buffer size =  2048.00 MiB\n",
            "llama_init_from_model: KV self size  = 2048.00 MiB, K (f16): 1024.00 MiB, V (f16): 1024.00 MiB\n",
            "llama_init_from_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_init_from_model:        CPU compute buffer size =   296.01 MiB\n",
            "llama_init_from_model: graph nodes  = 1030\n",
            "llama_init_from_model: graph splits = 1\n",
            "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '15'}\n",
            "Using fallback chat format: llama-2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extractQueryAnsFromPdf(query, pdf_path):\n",
        "  filename_fn = lambda filename: {'file_name': os.path.basename(pdf_path)}\n",
        "  loader = SimpleDirectoryReader(input_files=[pdf_path], file_metadata=filename_fn)\n",
        "  documents = loader.load_data()\n",
        "\n",
        "  # Indexing\n",
        "  start_time = time.time()\n",
        "\n",
        "  index = VectorStoreIndex.from_documents(documents, embed_model=embed_model, llm=llm)\n",
        "\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  print(f\"Elapsed indexing time: {elapsed_time:.2f} s\")\n",
        "\n",
        "  query_str = \"What are the data the company collect?\"\n",
        "  query_engine = index.as_query_engine(similarity_top_k=1, llm=llm)\n",
        "  # use this for testing\n",
        "  vector_retriever = index.as_retriever(similarity_top_k=1)\n",
        "  response = query_engine.query(query_str)\n",
        "  return str(response)"
      ],
      "metadata": {
        "id": "MUYXeL6M1r4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = HOME_DIR + \"/Codes/Privacy Policies/12M recruiting.pdf\"\n",
        "query = \"What are the data the company collect?\"\n",
        "response = extractQueryAnsFromPdf(query, pdf_path)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bmbu8Yh420a9",
        "outputId": "63db6608-6ad7-4a7c-9c3a-18cd354e0f13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed indexing time: 0.35 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =   12982.67 ms\n",
            "llama_perf_context_print: prompt eval time =   12982.50 ms /    50 tokens (  259.65 ms per token,     3.85 tokens per second)\n",
            "llama_perf_context_print:        eval time =    7777.33 ms /    18 runs   (  432.07 ms per token,     2.31 tokens per second)\n",
            "llama_perf_context_print:       total time =   20767.72 ms /    68 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The company collects data on customer demographics, website usage, and purchases.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "privacyPolicyPaths = glob(HOME_DIR + '/Codes/Privacy Policies/*.pdf')\n",
        "len(privacyPolicyPaths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-dy18cB3JVm",
        "outputId": "c79e587b-9469-4413-9f3b-60fde1fb9744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictAll = []\n",
        "for pdf_path in privacyPolicyPaths:\n",
        "  query = \"What are the data the company collect?\"\n",
        "  response = extractQueryAnsFromPdf(query, pdf_path)\n",
        "  print(response)\n",
        "\n",
        "  dictAll.append({'file_name': os.path.basename(pdf_path), 'response': response})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQCy33po4niB",
        "outputId": "109f27d7-315f-4a90-9c38-8da9bc4586be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed indexing time: 0.42 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 49 prefix-match hit, remaining 1 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   12982.67 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =   26535.49 ms /    59 runs   (  449.75 ms per token,     2.22 tokens per second)\n",
            "llama_perf_context_print:       total time =   26560.97 ms /    60 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Based on the context information provided, the company collects data on user behavior on its website, including page views, time spent on the site, and clicks on links. This information is used to improve the user experience and tailor the site to the user's preferences.\n",
            "Elapsed indexing time: 11.34 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 16 prefix-match hit, remaining 644 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   12982.67 ms\n",
            "llama_perf_context_print: prompt eval time =  187272.20 ms /   644 tokens (  290.80 ms per token,     3.44 tokens per second)\n",
            "llama_perf_context_print:        eval time =  117631.84 ms /   255 runs   (  461.30 ms per token,     2.17 tokens per second)\n",
            "llama_perf_context_print:       total time =  305057.68 ms /   899 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accenture collects the following data:\n",
            "\n",
            "1. Account data: Title, name, email, address, telephone number, and business address.\n",
            "2. Individual(s) appointed by Your Organization to represent Your Organization in and during the contractual relationship and to otherwise interact with Accenture.\n",
            "3. Information for entering into a contract for the provision of the applicable MxDR Service.\n",
            "4. Communication with Your Organization in the provision of the applicable MxDR Service.\n",
            "5. Communication with Your Organization in the event of complaints.\n",
            "6. Invoicing and receiving payment for the applicable MxDR Service.\n",
            "7. Exploring future contracting opportunities.\n",
            "8. Performing and analyzing surveys and feedback.\n",
            "9. Exercising or defending Accenture's rights in the context of legal claims/disputes with Your Organization.\n",
            "10. Legitimate interest of both Accenture and Your Organization for having the MxDR Service contract in place properly performed.\n",
            "111. Legitimate interest of Accenture for ensuring the proper functioning of its business operations and exercise its legal rights in\n",
            "Elapsed indexing time: 19.93 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 15 prefix-match hit, remaining 485 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   12982.67 ms\n",
            "llama_perf_context_print: prompt eval time =  125313.12 ms /   485 tokens (  258.38 ms per token,     3.87 tokens per second)\n",
            "llama_perf_context_print:        eval time =  119337.03 ms /   255 runs   (  467.99 ms per token,     2.14 tokens per second)\n",
            "llama_perf_context_print:       total time =  244791.61 ms /   740 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The company collects the following data:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Elapsed indexing time: 21.98 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 15 prefix-match hit, remaining 294 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   12982.67 ms\n",
            "llama_perf_context_print: prompt eval time =   74404.50 ms /   294 tokens (  253.08 ms per token,     3.95 tokens per second)\n",
            "llama_perf_context_print:        eval time =   48328.46 ms /   116 runs   (  416.62 ms per token,     2.40 tokens per second)\n",
            "llama_perf_context_print:       total time =  122788.47 ms /   410 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The company collects the following data:\n",
            "\n",
            "* Contact information\n",
            "* Information related to employment\n",
            "* Personal data available through social media (e.g. Facebook, LinkedIn, Twitter, Google)\n",
            "* Payment information when paying for certain MarketStar services\n",
            "* Technical information and navigational information of users who register to use their in-house applications (e.g. PartnerDynamicsÂ® and Game Plan)\n",
            "* Information related to employment (e.g. name, email address, company name, address, phone number)\n",
            "Elapsed indexing time: 12.80 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 15 prefix-match hit, remaining 393 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   12982.67 ms\n",
            "llama_perf_context_print: prompt eval time =  107092.46 ms /   393 tokens (  272.50 ms per token,     3.67 tokens per second)\n",
            "llama_perf_context_print:        eval time =   15306.97 ms /    26 runs   (  588.73 ms per token,     1.70 tokens per second)\n",
            "llama_perf_context_print:       total time =  122411.17 ms /   419 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Based on the provided context information, the company Concentrix collects the following data:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Elapsed indexing time: 4.40 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 15 prefix-match hit, remaining 369 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   12982.67 ms\n",
            "llama_perf_context_print: prompt eval time =   93773.18 ms /   369 tokens (  254.13 ms per token,     3.94 tokens per second)\n",
            "llama_perf_context_print:        eval time =    9680.13 ms /    24 runs   (  403.34 ms per token,     2.48 tokens per second)\n",
            "llama_perf_context_print:       total time =  103463.50 ms /   393 tokens\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The company collects the following data:\n",
            "\n",
            "Personal data: name, email, and phone number.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictAll"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdVNqOHUA4Qp",
        "outputId": "bd48dab7-df0c-47b3-9245-3b306d311171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'file_name': '12M recruiting.pdf',\n",
              "  'response': \"\\nBased on the context information provided, the company collects data on user behavior on its website, including page views, time spent on the site, and clicks on links. This information is used to improve the user experience and tailor the site to the user's preferences.\"},\n",
              " {'file_name': 'Accenture-Privacy-Statement-MDR-English.pdf',\n",
              "  'response': \"\\nAccenture collects the following data:\\n\\n1. Account data: Title, name, email, address, telephone number, and business address.\\n2. Individual(s) appointed by Your Organization to represent Your Organization in and during the contractual relationship and to otherwise interact with Accenture.\\n3. Information for entering into a contract for the provision of the applicable MxDR Service.\\n4. Communication with Your Organization in the provision of the applicable MxDR Service.\\n5. Communication with Your Organization in the event of complaints.\\n6. Invoicing and receiving payment for the applicable MxDR Service.\\n7. Exploring future contracting opportunities.\\n8. Performing and analyzing surveys and feedback.\\n9. Exercising or defending Accenture's rights in the context of legal claims/disputes with Your Organization.\\n10. Legitimate interest of both Accenture and Your Organization for having the MxDR Service contract in place properly performed.\\n111. Legitimate interest of Accenture for ensuring the proper functioning of its business operations and exercise its legal rights in\"},\n",
              " {'file_name': 'cognizant-privacy-notice.pdf',\n",
              "  'response': '\\nThe company collects the following data:\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'},\n",
              " {'file_name': 'MarketStar Privacy Policy (Privacy Shield under MarketStar Corporation 08.20).pdf',\n",
              "  'response': '\\nThe company collects the following data:\\n\\n* Contact information\\n* Information related to employment\\n* Personal data available through social media (e.g. Facebook, LinkedIn, Twitter, Google)\\n* Payment information when paying for certain MarketStar services\\n* Technical information and navigational information of users who register to use their in-house applications (e.g. PartnerDynamicsÂ® and Game Plan)\\n* Information related to employment (e.g. name, email address, company name, address, phone number)'},\n",
              " {'file_name': 'CNX-California-Privacy-Policy-v2.0.pdf',\n",
              "  'response': ' Based on the provided context information, the company Concentrix collects the following data:\\n\\n\\n\\n\\n\\n\\n\\n'},\n",
              " {'file_name': 'ENG_Personal_data_protection_policy_Whistleblower_Channel_2023.pdf',\n",
              "  'response': '\\nThe company collects the following data:\\n\\nPersonal data: name, email, and phone number.\\n'}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dictionary to DataFrame\n",
        "df = pd.DataFrame(dictAll)\n",
        "\n",
        "# Save to CSV\n",
        "df.to_excel(\"/content/drive/MyDrive/PhD research/LLM Privacy Policy/Codes/informationCollection.xlsx\", index=False)"
      ],
      "metadata": {
        "id": "ZS_65Bi05LAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "KHEPjDlcBLDX",
        "outputId": "42fff334-20e2-4e3f-eef3-a700b89a49df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           file_name  \\\n",
              "0                                 12M recruiting.pdf   \n",
              "1        Accenture-Privacy-Statement-MDR-English.pdf   \n",
              "2                       cognizant-privacy-notice.pdf   \n",
              "3  MarketStar Privacy Policy (Privacy Shield unde...   \n",
              "4             CNX-California-Privacy-Policy-v2.0.pdf   \n",
              "5  ENG_Personal_data_protection_policy_Whistleblo...   \n",
              "\n",
              "                                            response  \n",
              "0  \\nBased on the context information provided, t...  \n",
              "1  \\nAccenture collects the following data:\\n\\n1....  \n",
              "2  \\nThe company collects the following data:\\n\\n...  \n",
              "3  \\nThe company collects the following data:\\n\\n...  \n",
              "4   Based on the provided context information, th...  \n",
              "5  \\nThe company collects the following data:\\n\\n...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-944a0e39-833a-43b1-a009-3ef4a45cea46\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_name</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12M recruiting.pdf</td>\n",
              "      <td>\\nBased on the context information provided, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Accenture-Privacy-Statement-MDR-English.pdf</td>\n",
              "      <td>\\nAccenture collects the following data:\\n\\n1....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cognizant-privacy-notice.pdf</td>\n",
              "      <td>\\nThe company collects the following data:\\n\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MarketStar Privacy Policy (Privacy Shield unde...</td>\n",
              "      <td>\\nThe company collects the following data:\\n\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CNX-California-Privacy-Policy-v2.0.pdf</td>\n",
              "      <td>Based on the provided context information, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ENG_Personal_data_protection_policy_Whistleblo...</td>\n",
              "      <td>\\nThe company collects the following data:\\n\\n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-944a0e39-833a-43b1-a009-3ef4a45cea46')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-944a0e39-833a-43b1-a009-3ef4a45cea46 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-944a0e39-833a-43b1-a009-3ef4a45cea46');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-30206914-209d-4d38-ad26-fe3a480187de\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-30206914-209d-4d38-ad26-fe3a480187de')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-30206914-209d-4d38-ad26-fe3a480187de button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_807edaea-3250-4c76-af35-9d5d070b9621\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_807edaea-3250-4c76-af35-9d5d070b9621 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"12M recruiting.pdf\",\n          \"Accenture-Privacy-Statement-MDR-English.pdf\",\n          \"ENG_Personal_data_protection_policy_Whistleblower_Channel_2023.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"\\nBased on the context information provided, the company collects data on user behavior on its website, including page views, time spent on the site, and clicks on links. This information is used to improve the user experience and tailor the site to the user's preferences.\",\n          \"\\nAccenture collects the following data:\\n\\n1. Account data: Title, name, email, address, telephone number, and business address.\\n2. Individual(s) appointed by Your Organization to represent Your Organization in and during the contractual relationship and to otherwise interact with Accenture.\\n3. Information for entering into a contract for the provision of the applicable MxDR Service.\\n4. Communication with Your Organization in the provision of the applicable MxDR Service.\\n5. Communication with Your Organization in the event of complaints.\\n6. Invoicing and receiving payment for the applicable MxDR Service.\\n7. Exploring future contracting opportunities.\\n8. Performing and analyzing surveys and feedback.\\n9. Exercising or defending Accenture's rights in the context of legal claims/disputes with Your Organization.\\n10. Legitimate interest of both Accenture and Your Organization for having the MxDR Service contract in place properly performed.\\n111. Legitimate interest of Accenture for ensuring the proper functioning of its business operations and exercise its legal rights in\",\n          \"\\nThe company collects the following data:\\n\\nPersonal data: name, email, and phone number.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}